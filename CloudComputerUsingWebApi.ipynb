{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ddb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "from flask import Flask, request, jsonify,send_from_directory\n",
    "import json\n",
    "#import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289e6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo code \n",
    "app = Flask(__name__)\n",
    "\n",
    "# global variables\n",
    "global train_logs \n",
    "softmax = nn.Softmax(dim=0)\n",
    "\n",
    "@app.route('/')\n",
    "def base():\n",
    "    return \"Base Test is OK\" # may return a html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4008728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabel(onehats,dim):\n",
    "    labelcoding = []\n",
    "    for code in onehats:\n",
    "        value = 0\n",
    "        for idx in range(dim):\n",
    "            if(code[idx]==1):\n",
    "                value = idx\n",
    "        labelcoding.append(value)\n",
    "    labelcoding = torch.FloatTensor(labelcoding) \n",
    "    return labelcoding  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09cc1a",
   "metadata": {},
   "source": [
    "# Modle 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c04e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface for users to upload dataset\n",
    "@app.route('/dataset_1', methods=[\"POST\"])\n",
    "def getDataSet_1():\n",
    "    global inputs_1\n",
    "    global labels_1\n",
    "    request_content = request.get_json()    \n",
    "    #print(type(request_content))\n",
    "    \n",
    "    if(isinstance(request_content, str)):\n",
    "        request_content = json.loads(request_content)\n",
    "        #print(type(request_content))\n",
    "    \n",
    "    inputs_1 = request_content[\"inputs\"]\n",
    "    labels_1 = request_content[\"labels\"]\n",
    "    \n",
    "    inputs_1 = torch.FloatTensor(inputs_1)\n",
    "    labels_1 = torch.FloatTensor(labels_1)    \n",
    "    \n",
    "    response = app.response_class(\n",
    "        response=json.dumps(request_content),\n",
    "        status=200,\n",
    "        mimetype='application/json'\n",
    "    )\n",
    "        \n",
    "    return response\n",
    "    \n",
    "# if dataset is meta format, like image, json, yaml, ...\n",
    "#   students may implement the approach to save the file or store data into an NoSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322a763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n",
      "<bound method Module.parameters of MyModel(\n",
      "  (linear_1): Linear(in_features=7, out_features=20, bias=True)\n",
      "  (linear_2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear_3): Linear(in_features=20, out_features=2, bias=True)\n",
      "  (LogSoftmax): LogSoftmax(dim=0)\n",
      "  (relu): ReLU()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# create model_1\n",
    "\n",
    "# Make device agnostic code\n",
    "device = \"cpu\"# Enable CUDA if possible\n",
    "print(f\"device is {device}\")\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        hidden1_dim = 20\n",
    "        hidden2_dim = 20\n",
    "\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden1_dim)\n",
    "        self.linear_2 = nn.Linear(hidden1_dim, hidden2_dim)\n",
    "        self.linear_3 = nn.Linear(hidden2_dim, output_dim)\n",
    "\n",
    "        self.LogSoftmax = nn.LogSoftmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.linear_1(inputs).requires_grad_()\n",
    "        outputs = self.LogSoftmax(outputs).requires_grad_()\n",
    "        outputs = self.linear_2(outputs).requires_grad_()\n",
    "        outputs = self.LogSoftmax(outputs).requires_grad_()        \n",
    "        outputs = self.linear_3(outputs).requires_grad_()\n",
    "        outputs = self.LogSoftmax(outputs).requires_grad_()\n",
    "\n",
    "        return outputs\n",
    "        \n",
    "# 4. Create an instance of the model and send it to target device\n",
    "torch.manual_seed(42)\n",
    "model_1 = MyModel(7,2).to(device)\n",
    "\n",
    "print(model_1.parameters)# Type of parameter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b919e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loss function\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "# Create an optimizer\n",
    "learning_rate = 0.0001\n",
    "optimizer_1 = torch.optim.SGD(params=model_1.parameters(),lr=learning_rate)\n",
    "\n",
    "@app.route(\"/train_1\", methods=['GET', 'POST'])\n",
    "def trainModel_1():\n",
    "    global train_logs_1\n",
    "    global inputs_1\n",
    "    global labels_1\n",
    "    \n",
    "    train_logs_1 = []    \n",
    "    num_epochs = 1000 # Train for longer\\\n",
    "    learning_rate = 0.01\n",
    "    softmax = nn.Softmax(dim=0)\n",
    "    \n",
    "    # Put data to target device\n",
    "    # device = \"cpu\" if torch.cuda.is_available() else \"cpu\"# Enable CUDA if possible\n",
    "    device = \"cpu\"\n",
    "    print(f\"device is {device}\")\n",
    "    \n",
    "    model_1.to(device)\n",
    "    \n",
    "    labels_1 = encodeLabel(labels_1,2)\n",
    "    inputs_1, labels_1 = inputs_1.to(device), labels_1.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        predicts = model_1(inputs_1)\n",
    "        loss = criterion(predicts,labels_1.long() )  # https://www.cnblogs.com/blogwangwang/p/12018897.html\n",
    "        optimizer_1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_1.step()\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            train_logs_1.append(f\"Epoch: {epoch} | Loss: {loss:.5f}\")\n",
    "    \n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a8cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/log_1\", methods=['GET'])\n",
    "def getTrainingLog_1():    \n",
    "    response = app.response_class(\n",
    "        response=json.dumps(train_logs_1),\n",
    "        status=200,\n",
    "        mimetype='application/json'\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9902ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/inference_1\", methods=['POST'])\n",
    "def inference_1():\n",
    "    device = \"cpu\"\n",
    "    request_content = request.get_json() \n",
    "    if(isinstance(request_content, str)):\n",
    "        request_content = json.loads(request_content)\n",
    "    input_data = request_content[\"input\"]\n",
    "    \n",
    "    print(input_data)\n",
    "    \n",
    "    input_data = torch.FloatTensor(input_data)\n",
    "    input_data = input_data.to(device)\n",
    "    result = softmax(model_1(input_data)).tolist()\n",
    "    \n",
    "    response = app.response_class(\n",
    "        response=json.dumps(result),\n",
    "        status=200,\n",
    "        mimetype='application/json'\n",
    "    ) \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab56db47",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5bc1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface for users to upload dataset\n",
    "@app.route('/dataset_2', methods=[\"POST\"])\n",
    "def getDataSet():\n",
    "    global inputs_2\n",
    "    global labels_2 \n",
    "    request_content = request.get_json()    \n",
    "    #print(type(request_content))\n",
    "    \n",
    "    if(isinstance(request_content, str)):\n",
    "        request_content = json.loads(request_content)\n",
    "        #print(type(request_content))\n",
    "    \n",
    "    inputs_2 = request_content[\"inputs\"]\n",
    "    labels_2 = request_content[\"labels\"]\n",
    "    \n",
    "    inputs_2 = torch.FloatTensor(inputs_2)\n",
    "    labels_2 = torch.FloatTensor(labels_2)    \n",
    "    \n",
    "    response = app.response_class(\n",
    "        response=json.dumps(request_content),\n",
    "        status=200,\n",
    "        mimetype='application/json'\n",
    "    )\n",
    "        \n",
    "    return response\n",
    "    \n",
    "# if dataset is meta format, like image, json, yaml, ...\n",
    "#   students may implement the approach to save the file or store data into an NoSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec29d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n",
      "<bound method Module.parameters of MyModel(\n",
      "  (linear_1): Linear(in_features=7, out_features=20, bias=True)\n",
      "  (linear_2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear_3): Linear(in_features=20, out_features=2, bias=True)\n",
      "  (LogSoftmax): LogSoftmax(dim=0)\n",
      "  (relu): ReLU()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# create model 2\n",
    "\n",
    "# Make device agnostic code\n",
    "device = \"cpu\"# Enable CUDA if possible\n",
    "print(f\"device is {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_2 = MyModel(7,2).to(device)\n",
    "\n",
    "print(model_2.parameters)# Type of parameter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01e41e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loss function\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "# Create an optimizer\n",
    "learning_rate = 0.0001\n",
    "optimizer_2 = torch.optim.SGD(params=model_2.parameters(),lr=learning_rate)\n",
    "\n",
    "@app.route(\"/train_2\", methods=['GET', 'POST'])\n",
    "def trainModel_2():\n",
    "    global train_logs_2\n",
    "    global inputs_2\n",
    "    global labels_2\n",
    "    \n",
    "    train_logs_2 = []    \n",
    "    num_epochs = 3000 # Train for longer\\\n",
    "    learning_rate = 0.01\n",
    "    softmax = nn.Softmax(dim=0)\n",
    "    \n",
    "    # Put data to target device\n",
    "    # device = \"cpu\" if torch.cuda.is_available() else \"cpu\"# Enable CUDA if possible\n",
    "    device = \"cpu\"\n",
    "    print(f\"device is {device}\")\n",
    "    \n",
    "    model_2.to(device)\n",
    "    \n",
    "    labels_2=encodeLabel(labels_2,2)\n",
    "    inputs_2, labels_2 = inputs_2.to(device), labels_2.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        predicts = model_2(inputs_2)\n",
    "        loss = criterion(predicts,labels_2.long() )  # https://www.cnblogs.com/blogwangwang/p/12018897.html\n",
    "        optimizer_2.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_2.step()\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            train_logs_2.append(f\"Epoch: {epoch} | Loss: {loss:.5f}\")\n",
    "    \n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4353eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/trainedModel_2\", methods=['GET'])\n",
    "def getTrainedModel_2():\n",
    "    x = [1,2,3]\n",
    "    x = torch.FloatTensor(x).to(device)\n",
    "    model_2.eval()\n",
    "    torch.onnx.export(model_2,x,\"trainedModel.onnx\")\n",
    "    \n",
    "    try:\n",
    "        return send_from_directory('' , 'trainedModel.onnx', as_attachment=True)\n",
    "    except FileNotFoundError:\n",
    "        abort(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d719813",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/log_2\", methods=['GET'])\n",
    "def getTrainingLog_2():    \n",
    "    response = app.response_class(\n",
    "        response=json.dumps(train_logs_2),\n",
    "        status=200,\n",
    "        mimetype='application/json'\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bebd85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/inference_2\", methods=['POST'])\n",
    "def inference_2():\n",
    "    device = \"cpu\"\n",
    "    request_content = request.get_json() \n",
    "    if(isinstance(request_content, str)):\n",
    "        request_content = json.loads(request_content)\n",
    "    input_data = request_content[\"input\"]\n",
    "    \n",
    "    input_data = torch.FloatTensor(input_data)\n",
    "    input_data = input_data.to(device)\n",
    "    result = softmax(model_2(input_data)).tolist()\n",
    "    \n",
    "    response = app.response_class(\n",
    "        response=json.dumps(result),\n",
    "        status=200,\n",
    "        mimetype='application/json'\n",
    "    ) \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567aeafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://172.17.0.17:5000/ (Press CTRL+C to quit)\n",
      "192.168.2.102 - - [26/Dec/2023 11:16:03] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.2.102 - - [26/Dec/2023 11:16:03] \"POST /dataset_2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.2.102 - - [26/Dec/2023 11:21:48] \"GET /train_2 HTTP/1.1\" 200 -\n",
      "192.168.2.102 - - [26/Dec/2023 11:21:48] \"GET /log_2 HTTP/1.1\" 200 -\n",
      "192.168.2.102 - - [26/Dec/2023 11:21:48] \"POST /inference_2 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Run up your Web API Server\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0',port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
